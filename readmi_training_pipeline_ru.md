# Описание тренировочного пайплайна: методология и этапы

## Общая схема

В этом документе описан тренировочный пайплайн для задачи прогнозирования неблагоприятных исходов на основе клинических и морфологических данных. Основной метод — `bootstrap_validation`, обеспечивающий устойчивую оценку модели и коррекцию оптимизма.

## Источники данных

- **Тренировочные данные:** синтетический датасет, полученный с помощью современных методов семплирования (см. `readmi_synthetic_data.md`).
- **Тестовые данные:** реальные, неиспользованные в обучении данные пациентов для честной валидации.

## Основные этапы

1. **Подготовка данных:**
   - Для обучения используется синтетика, что позволяет устранить дисбаланс классов и увеличить объём выборки.
   - Реальные данные резервируются для финального тестирования и оценки.
2. **Обучение модели:**
    - Ключевой этап — метод `bootstrap_validation`, реализующий бутстрэп-валидацию (bootstrap validation). Это статистический подход, при котором исходная обучающая выборка многократно пересэмплируется с возвращением (bootstrap-выборки). Для каждой такой выборки:
       1. Формируется новая обучающая подвыборка (in-bag), а оставшиеся наблюдения, не попавшие в неё, образуют out-of-bag (OOB) подвыборку для тестирования.
       2. На in-bag данных обучается модель, а затем она тестируется на OOB-наблюдениях, что позволяет получить независимую оценку качества без выделения отдельной тестовой выборки.
       3. Для каждой итерации вычисляются метрики качества (ROC-AUC, PR-AUC) как на обучающей, так и на OOB-выборке.
       4. Итоговая оценка корректируется на оптимизм: средняя разница между in-bag и OOB метриками вычитается из финального результата на всей обучающей выборке.
    - Для обучения используется AutoGluon TabPFNv2 — современный AutoML-фреймворк, позволяющий автоматически подбирать и обучать модели табличных данных. TabPFNv2 — это одна из самых продвинутых моделей для задач классификации и регрессии, основанная на нейросетевых архитектурах и ансамблях.
    - Все этапы, параметры, пути к моделям, а также промежуточные и финальные результаты логируются с помощью встроенного логгера Python. Это обеспечивает прозрачность, воспроизводимость и удобство анализа.
3. **Оценка качества:**
   - Для каждого bootstrap-итерации вычисляются ROC-AUC и PR-AUC для обучающей (in-bag) и тестовой (OOB) выборок.
   - Проводится коррекция оптимизма: разница между in-bag и OOB метриками усредняется и вычитается из финального результата на всей обучающей выборке.
   - Итоговые скорректированные метрики отражают реальную обобщающую способность модели.
4. **Leaderboard и логирование:**
   - После обучения сохраняется leaderboard с результатами в Excel-файл в папке модели.
   - Все ключевые этапы, пути и результаты логируются для воспроизводимости.

## Преимущества подхода

- **Устойчивость:** bootstrap validation даёт более надёжную оценку качества, особенно при малых или несбалансированных выборках.
- **Прозрачность:** все этапы логируются, результаты сохраняются для анализа.
- **Разделение train/test:** синтетика используется только для обучения, реальные данные — для финальной оценки, что исключает утечку информации.

## Примерный workflow

1. Генерация синтетических данных (см. `readmi_synthetic_data.md`).
2. Обучение модели методом `bootstrap_validation` на синтетике.
3. Оценка на реальных данных и сохранение leaderboard.

---
*Для подробностей см. код и логи. Замените плейсхолдеры на реальные результаты и графики по мере необходимости.*

## Результаты и статистика по логам

### Сводка логов

- Данные загружены: backend/data/resampled_data_smote.csv (синтетика, train)
- Данные загружены: backend/data/features.csv (реальные, test)
- Запущена bootstrap-валидация: 300 итераций
- Прогресс логируется каждые 25 итераций
- Пример leaderboard (AutoGluon):

| model                | score_test | score_val | eval_metric | pred_time_test | pred_time_val | fit_time | ... |
|----------------------|------------|-----------|-------------|---------------|--------------|----------|-----|
| RealTabPFN-v2.5      | 1.0        | 1.0       | accuracy    | 0.246         | 0.220        | 0.088    | ... |
| WeightedEnsemble_L2  | 1.0        | 1.0       | accuracy    | 0.247         | 0.220        | 0.089    | ... |

### Финальные результаты

- Явный ROC-AUC: 1.000
- Оптимизм: 0.001
- Скорректированный ROC-AUC: 0.999
- Явный PR-AUC: 1.000
- Оптимизм: 0.001
- Скорректированный PR-AUC: 0.999

Все результаты, leaderboards и логи сохраняются для воспроизводимости и последующего анализа.
